{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차역전파법 구현하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞절에서 구현한 계층(Affine, activation, Sofmax layer)을 조합하면 레고 블록 조합하든 신경망을 구축할 수 있음 \n",
    "![](./images/fig_5-28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 학습의 전체 그림 (p.180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전제 \n",
    "신경망에는 적응 가능한 가중치<sup>**W**</sup>와 편향<sup>**B**</sup>가 있음 \n",
    "> 가중치와 편향을 훈련 데이터에 적응하도록 튜닝하는 과정: \n",
    "   * 학습(learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1단계 - 미니배치 (p. 102, 115)\n",
    "훈련 데이터 중 일부를 무작위로 가져옴 \n",
    "  * 이렇게 선별한 데이터가 미니배치<sup>mini-batch</sup>\n",
    "> 그 미니배치의 손실 함수 값을 줄이는 것이 목표! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2단계 - 기울기 산출 \n",
    "미니배치의 손실 함수 값을 줄이기 위한 방향 지표가 필요함. \n",
    "  * 이를 위해 각 가중치 매개변수($w_{1} \\; w_{2} \\; ...\\; w_{n}$)에 대한 손실함수의 기울기(=미분)을 구함 \n",
    "> 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시함 (p.129) <br/>\n",
    "> $- \\frac{\\partial L}{\\partial \\mathbf{W}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3단계 - 매개변수 갱신 (feat. 경사하강법, p.129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 매개변수를 기울기 방향으로 아주 조금 갱신함(손실 함수를 최소화 시키는 방향이니까)\n",
    "> $\\mathbf{W}=\\mathbf{W}-\\eta \\frac{\\partial L}{\\partial \\mathbf{W}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4단계 - 반복 \n",
    "1 ~ 3단계를 반복함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/fig_NN_learning_process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5장에서 공부한 내용은 결국 $\\frac{\\partial L}{\\partial \\mathbf{W}}$을 구하기 위함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial L}{\\partial \\mathbf{W}}$ 구하는 방법 \n",
    "\n",
    "> (1) 수치 미분(ch.4) - 계산 속도 느림 (p.129)<br/>\n",
    "\n",
    "> (2) 해석 미분(ch.4, 5) by <span style=\"color:red\">Backpropagation</span> with computational graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제부터 가중치에 대한 손실함수 기울기( $\\frac{\\partial L}{\\partial \\mathbf{W}}$)는 Backpropagation으로 구함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
