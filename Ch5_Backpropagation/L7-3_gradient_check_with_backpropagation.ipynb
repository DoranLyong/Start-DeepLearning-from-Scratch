{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차역전파법으로 구한 기울기 검증하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(p. 184)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter4~5를 통해 기울기<sup>gradient</sup>를 구한느 방법 두 가지를 공부함  \n",
    "> (1) 수치 미분(p.121) - 계산 느림 \n",
    "\n",
    "> (2) 해석학 미분 &rarr; backpropagation with computational graph\n",
    "  * 오류역전파법을 사용하면 매개변수가 많아도 효율적으로 계산 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래서 이제부터는 gradient decent를 위한 기울기 계산은 bacpropagation을 사용함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 그러면 수치 미분은 아무 쓸모가 없는거임? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 함수를 전부 해석학적으로 미분할 수 있는것도 아니고... <br/>\n",
    "정말 무쓸모인가?  <br/>\n",
    "\n",
    "<span style=\"color:red\">No No No</span> <br/>\n",
    "> 수치 미분은 bacpropagation을 정확히 구현했는지 확인하기 위해 필요함 \n",
    "\n",
    "\n",
    "__i.e)__ network model에 대한 <span style=\"color:blue\">backpropagation 구현을 잘 했는지 검사</span>할 때 씀 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기울기 검증(gradient check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__수치 미분의 장점__ : 구현이 쉽다 \n",
    "> * 수치 미분을 코딩할 때는 버그가 숨어 있기 어려움 <br/>\n",
    "\n",
    "backpropagation은 계층 블록을 쌓다보면 복잡해져서 사람이 실수할 수 있음.<br/>\n",
    "그래서 <span style=\"color:red\">수치 미분의 결과</span>와 <span style=\"color:blue\">backpropagation의 결과</span>를 비교하여 backpropagation을 제대로 구현했는지 검증함.\n",
    "> 이같이 두 방식으로 구한 기울기가 일치함<sup>(__엄밀히 말해 거의 같음__)</sup>을 확인하는 작업을 __기울기 확인__<sup>gradient check</sup>이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient check 코드 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TwoLayerNet](https://github.com/DoranLyong/Start_deepLearning_from_floor-/blob/master/Ch5_Backpropagation/L7-2_Neural_Network_with_Backpropagation.ipynb) 클래스 정의 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[load_mnist](https://github.com/DoranLyong/Start_deepLearning_from_floor-/blob/master/Ch3_NeuralNet/L13_MNIST_data_img_load_into_numpy.ipynb) 함수 (p. 97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "\n",
    "# 계산 검증을 위해 일부 데이터만 불러옴 \n",
    "x_batch = x_train[:3]    # 훈련 데이터 \n",
    "t_batch = t_train[:3]    # 라벨링 데이터 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기울기 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)   # 수치 미분 \n",
    "grad_backprop = network.gradient(x_batch, t_batch)              # 해석 미분 by backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 방식으로 $\\frac{\\partial L}{\\partial \\mathbf{W}}$ 구함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 가중치 및 편향의 절대 오차의 평균\n",
    "각 가중치 및 편향의 차이의 절대값을 구한 후, 그 절대값들의 평균을 계산 \n",
    "> average( \\| 역전파가중치 - 수치미분가중치 \\| )\n",
    "\n",
    "> average( \\| 역전파편향 - 수치미분편향  \\| )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1에 대한 차이:3.3996849984351894e-10\n",
      "b1에 대한 차이:2.1597023282661324e-09\n",
      "W2에 대한 차이:4.837028355711433e-09\n",
      "b2에 대한 차이:1.3998314324914495e-07\n"
     ]
    }
   ],
   "source": [
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) ) # \n",
    "    print(key + \"에 대한 차이\"+ \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__결과 해석__ (p. 185) <br/> \n",
    "\n",
    "예를 들어 1층의 가중치 매개변수 W1에 대해 비교했을 때, 오차는 0.0000000xxxx 로 매우 낮음 \n",
    "> 이는 수치 미분과 오차역전파법으로 구한 기울기의 차이가 매우 작음을 의미 \n",
    "  * backpropagation이 잘 구현됨 \n",
    "  \n",
    "### backpropagation이 잘 설계된것을 확인 했으니 이제 믿고 사용하면 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W1', 'b1', 'W2', 'b2'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_numerical.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.00252762 -0.00170557  0.         -0.00187136\n",
      "  0.00043034 -0.00470567  0.0033343   0.          0.          0.00096062\n",
      " -0.00074439  0.          0.00574064  0.00044227  0.00413647  0.00084012\n",
      "  0.00274844 -0.00169966 -0.0049455   0.00708124 -0.00189469 -0.00365544\n",
      " -0.00205302  0.         -0.01014807 -0.00467748  0.          0.00176041\n",
      " -0.00072848  0.0071463  -0.00216384  0.00147821  0.00114942 -0.00253224\n",
      "  0.         -0.00735872  0.00203971 -0.00233744 -0.00150379  0.\n",
      "  0.00083065  0.0018489  -0.00103975 -0.00293315  0.          0.00140423\n",
      "  0.         -0.0033612 ]\n"
     ]
    }
   ],
   "source": [
    "print(grad_backprop['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.00252762 -0.00170557  0.         -0.00187135\n",
      "  0.00043034 -0.00470567  0.0033343   0.          0.          0.00096062\n",
      " -0.00074439  0.          0.00574063  0.00044227  0.00413647  0.00084012\n",
      "  0.00274844 -0.00169965 -0.0049455   0.00708123 -0.00189469 -0.00365544\n",
      " -0.00205302  0.         -0.01014806 -0.00467748  0.          0.00176041\n",
      " -0.00072848  0.00714629 -0.00216383  0.00147821  0.00114942 -0.00253223\n",
      "  0.         -0.00735871  0.00203971 -0.00233744 -0.00150378  0.\n",
      "  0.00083065  0.00184889 -0.00103975 -0.00293314  0.          0.00140423\n",
      "  0.         -0.0033612 ]\n"
     ]
    }
   ],
   "source": [
    "print(grad_numerical['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
